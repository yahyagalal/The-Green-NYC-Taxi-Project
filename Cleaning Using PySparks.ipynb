{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec70f372",
   "metadata": {},
   "source": [
    "# Milestone 3 - Pre-processing and analysis with PySpark\n",
    "\n",
    "## Deadline - Sunday, 10th of December @11.59 pm \n",
    "\n",
    "The goal of this milestone is to preprocess the dataset 'New York yellow taxis' by performing basic data preparation and basic analysis to gain a better understanding of the data using PySpark.\n",
    "\n",
    "Use the same month and year you used for the green taxis in milestone 1. [Datasets](https://drive.google.com/drive/folders/1t8nBgbHVaA5roZY4z3RcAG1_JMYlSTqu?usp=sharing) (download the yellow taxis dataset).\n",
    "\n",
    "Important Notes:\n",
    "- You MUST use this notebook template/structure. not doing so will result in marks deduction.\n",
    "- You MUST have the cells run and output shown similar to milestone 1. I will NOT RUN YOUR NOTEBOOK.\n",
    "\n",
    "Submission guidelines: same as milestone 1.\n",
    "\n",
    "Notebook name must be same format as the file you named in miletsone 1. Just M3 instead of M1.\n",
    "\n",
    "IMPORTANT: You are only allowed to use PySpark unless explicitly told otherwise(i.e last task).\n",
    "\n",
    "Useful resource/documentation (highly recommended) - [PySpark examples](https://sparkbyexamples.com/pyspark-tutorial/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dd9327",
   "metadata": {},
   "source": [
    "## Weight dist.\n",
    "- Loading the dataset : 5%\n",
    "- Basic cleaning: 30%\n",
    "\t- column renaming: 10%\n",
    "\t- detect missing: 35%\n",
    "\t- Handle missing: 35%\n",
    "\t- Check missing : 20%\n",
    "- Analyses: 30%\n",
    "- Encoding: 20%\n",
    "- Lookup table: 10%\n",
    "- Writing the cleaned and lookup table back as parquet and csv files: 5%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373d9b0c",
   "metadata": {},
   "source": [
    "# Tasks:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd35a7dc",
   "metadata": {},
   "source": [
    "## Load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efa26f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050e3822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7eb86a5",
   "metadata": {},
   "source": [
    "### Preview first 20 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa27dab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b16df3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "361aa495",
   "metadata": {},
   "source": [
    "### How many partitions is this dataframe split into?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0151823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ca4e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cd45fad",
   "metadata": {},
   "source": [
    "## Basic cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e30192c",
   "metadata": {},
   "source": [
    "### rename all columns (replacing a space with an underscore, and making it lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a36b9c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d857b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b3afbda",
   "metadata": {},
   "source": [
    "### Detect and remove duplicates\n",
    "- Duplicates are trips with same pickup time,pickup location, dropoff time,drop off location and trip distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a08746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79a41cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe15c117",
   "metadata": {},
   "source": [
    "### check that there is are no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c169dd4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ac19c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76a487be",
   "metadata": {},
   "source": [
    "### Detect missing\n",
    "- Create a function that takes in the df and returns any data structrue of your choice(df/dict,list,tuple,etc) which has the name of the column and percentage of missing entries from the whole dataset.\n",
    "- Tip : storing the missing info as dict where the key is the column name and value is the percentage would be the easiest.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2291b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb209f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e459348",
   "metadata": {},
   "source": [
    "### Prinout the missing info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41010a35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e4b3e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ead65669",
   "metadata": {},
   "source": [
    "### Handle missing\n",
    "- For numerical features replace with 0.\n",
    "- For categorical/strings replace with 'Unknown'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d78a72f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e3a9c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4d54a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa139136",
   "metadata": {},
   "source": [
    "### check that there are no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17333948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2a0861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36ac1d9f",
   "metadata": {},
   "source": [
    "## Feature engineering - \n",
    "Write a function that adds the 3 following features. Use built in fucntions in PySpark (from the functions library) check lab 8, Avoid writing UDFs from scratch.\n",
    "- trip duration (the format/unit is up to you)\n",
    "- is_weekend. whether the trip occurred on Saturday or Sunday.\n",
    "- week number (relevant to the month and not year, i.e 1,2,3,4 nto 31,32,33...) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3fcc55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783d9bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a59334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a927246",
   "metadata": {},
   "source": [
    "### Preview the first 20 rows (only select the following features: pickup and droptime, and the 3 features you added). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9aae0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1b9b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5580ea4",
   "metadata": {},
   "source": [
    "## Analyses - Answer the following 5 questions (by showing the output and and a short 1-2 sentences regarding your observation/answer) \n",
    "\n",
    "MUST Use the PySpark SQL API.\n",
    "\n",
    "DO NOT explicitly write SQL queries. Doing so will result in 50% deduction (for the question). Check lab 7.\n",
    "\n",
    "You are free to add columns if it will help in answering a question and add useful info to the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1696d6",
   "metadata": {},
   "source": [
    "### 1- What is the average fare amount per payment type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97654b5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0175e1aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "281874a7",
   "metadata": {},
   "source": [
    "### 2- Do people tend to go on a longer trips during the weekend or weekdays?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc06dacb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c06966f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee349df0",
   "metadata": {},
   "source": [
    "### 3 - which day recorded the most trips?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4427c9ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414dff4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8dc3e82",
   "metadata": {},
   "source": [
    "### 4- What is the average \"total amount\" of trips with more than 2 passengers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceebb49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d090c1af",
   "metadata": {},
   "source": [
    "### 5- On average, when is it more likely that the tip is higher, when there are multiple passengers or just 1.?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ea2ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6034abd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee83fe0b",
   "metadata": {},
   "source": [
    "### 6- What is the most frequent route on the weekend. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448ae113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211d3ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfd702ec",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "- Label encode all categorical fetaures.\n",
    "- Create a lookup table for these label encoded features. You can use the same format/example as the lookup table in Milestone 1 description.\n",
    "\n",
    "(You are allowed to store and manipulate the lookup table as a pandas dataframe, it does not have to be a PySpark df).\n",
    "- Remove the original unencoded categorical features from the df after encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc07c545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0177519e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a810bca",
   "metadata": {},
   "source": [
    "### Preview first 20 rows of the label encoded features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54de3b3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640874a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "547d8fc3",
   "metadata": {},
   "source": [
    "### Preview first 20 rows of your lookup table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8374f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b20b295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcdd7830",
   "metadata": {},
   "source": [
    "### Load the cleaned PySpark df to a parquet file and the lookup table to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fbdb44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d45165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "846f97ac",
   "metadata": {},
   "source": [
    "## Bonus - Load the cleaned parquet file and lookup table into a Postgres database. \n",
    "\n",
    "Note that if you decide to do the bonus, you must include not only your notebook but the docker-compose.yaml file aswell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0334636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ef76b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "598c8f58",
   "metadata": {},
   "source": [
    "### Screenshot of the table existing in the database and a simple query such as `select count(*) from table_name` or `select * from table_name limit 10`\n",
    "\n",
    "(You can just copy paste the screenshots in the markdown cells below)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4082ea3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6329f74",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e30ecdbd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
